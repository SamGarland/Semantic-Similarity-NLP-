import spacy#==== Running file with 'en_core_web_md' =====#nlp = spacy.load('en_core_web_md')word1 = nlp("cat")word2 = nlp("monkey")word3 = nlp("banana")print(word1.similarity(word2))print(word3.similarity(word2))print(word3.similarity(word1))print("\n")#==== Note ====#"""The semantic similarity between cat and monkey is not surprising. Similarity between monkey and banana is very interesting because I would have considered this a pragmatic similarity i.e. a similarity in 'use' rather than in inherent 'meaning'.Furthermore, it's interesting to consider that there is some semantic similarity between banana and cat - is this because they are both nouns i.e. 'syntactic similarity' rather than because there similarity in meaning?"""#==== My own example ====#:word1 = nlp("swede")word2 = nlp("leaf")word3 = nlp("root")print(word1.similarity(word2))print(word3.similarity(word2))print(word3.similarity(word1))print("\n")# Interesting that spacy can't deal well with words with multiple meanings.tokens = nlp("cat apple monkey banana")for token1 in tokens:   for token2 in tokens:        print(token1.text, token2.text, token1.similarity(token2))print("\n")sentence_to_compare = "Why is my cat on the car"sentences = ["where did my dog go","Hello, there is my car","I\'ve lost my car in my car","I\'d like my boat back","I will name my dog Diana"]model_sentence = nlp(sentence_to_compare)for sentence in sentences:    similarity = nlp(sentence).similarity(model_sentence)    print(sentence + " - ", similarity)    #====== Running file with 'en_core_web_sm'=====##==== Note ====#"""The semantic similarity between cat, monkey and banana is greater than with 'en_core_web_md'.Cat and apple have a much higher semantic similarity, whereas monkey and banana are much lower, asare banana and apple. The similarity between different sentences is much lower with 'en_core_web_sm', this is because the model isn't as effective given that it doesn't have certain vectors loaded.I get the following message:"UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available."""nlp = spacy.load('en_core_web_sm')word1 = nlp("cat")word2 = nlp("monkey")word3 = nlp("banana")print("\n \n")print(word1.similarity(word2))print(word3.similarity(word2))print(word3.similarity(word1))print("\n")tokens = nlp("cat apple monkey banana")for token1 in tokens:   for token2 in tokens:        print(token1.text, token2.text, token1.similarity(token2))print("\n")sentence_to_compare = "Why is my cat on the car"sentences = ["where did my dog go","Hello, there is my car","I\'ve lost my car in my car","I\'d like my boat back","I will name my dog Diana"]model_sentence = nlp(sentence_to_compare)for sentence in sentences:    similarity = nlp(sentence).similarity(model_sentence)    print(sentence + " - ", similarity)